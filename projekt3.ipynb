{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T20:30:00.543627Z",
     "start_time": "2025-04-09T20:29:56.320675Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "from torch.utils.data import random_split\n",
    "import csv\n",
    "from PIL import Image"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div style=\"font-size: 40px\">\n",
    "data preparation\n",
    "</div>"
   ],
   "id": "336875e4073ad735"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8773f97620cd5b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T20:31:03.356617Z",
     "start_time": "2025-04-09T20:31:02.979838Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba klas: 50\n",
      "Nazwy klas: ['acoustic', 'antenna', 'bacteria', 'battery', 'bean', 'beetle', 'bicycle', 'birch', 'bird', 'bomb', 'bread', 'bridge', 'camera', 'carbon', 'cat', 'corn', 'crab', 'crocodilian', 'echinoderm', 'egg', 'elephant', 'fish', 'flower', 'frog', 'fungus', 'gauge', 'hammer', 'icecream', 'kangaroo', 'memorial', 'monkey', 'motor', 'nest', 'palm', 'pizza', 'pot', 'printer', 'saw', 'snake', 'spice', 'spider', 'spoon', 'squash', 'swine', 'tea', 'tomato', 'towel', 'truck', 'turtle', 'worm']\n",
      "Liczba obrazów treningowych: 88011\n"
     ]
    }
   ],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "full_dataset = ImageFolder(\"train/\", transform=train_transform)\n",
    "\n",
    "dataset_size = len(full_dataset)\n",
    "train_size = int(dataset_size * 0.92)\n",
    "val_size = dataset_size - train_size\n",
    "trainset, valset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=32, shuffle=True, num_workers=4)\n",
    "valloader = DataLoader(valset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "print(f\"Number of classes: {len(full_dataset.classes)}\")\n",
    "print(f\"Class names: {full_dataset.classes}\")\n",
    "print(f\"training images count: {len(trainset)}\")\n",
    "print(f\"testing images count: {len(valset)}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div style=\"font-size: 40px\">\n",
    "model architecture\n",
    "</div>"
   ],
   "id": "8c3ee1407648d00b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "\n",
    "        out += self.shortcut(residual)\n",
    "        out = F.relu(out)\n",
    "\n",
    "        return out"
   ],
   "id": "21ec7dd54c527998"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9afadc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        \n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        \n",
    "        out += self.shortcut(residual)\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2688c7e8fb10b0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T20:31:37.200085Z",
     "start_time": "2025-04-09T20:31:37.189466Z"
    }
   },
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.res1 = ResidualBlock(32, 64, stride=1)\n",
    "        self.res2 = ResidualBlock(64, 128, stride=1)\n",
    "        self.res3 = ResidualBlock(128, 256, stride=1)\n",
    "        self.res4 = ResidualBlock(256, 512, stride=1)\n",
    "\n",
    "        self.fc1 = nn.Linear(512 * 2 * 2, 1024)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        self.fc2 = nn.Linear(1024, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.pool4(F.relu(self.bn4(self.conv4(x))))\n",
    "        x = self.pool5(F.relu(self.bn5(self.conv5(x))))\n",
    "\n",
    "        x = x.view(-1, 512 * 7 * 7)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "603acdcef363b06c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T20:36:59.388485Z",
     "start_time": "2025-04-09T20:31:41.798386Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Używane urządzenie: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Used device: {device}\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "num_classes = len(full_dataset.classes)\n",
    "model = CNNModel(num_classes).to(device)\n",
    "\n",
    "model_path = 'model.pth'\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Loading existing model from {model_path}\")\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "else:\n",
    "    print(\"No existing model found. Initializing new model.\")"
   ],
   "id": "21a9b4df11a25ab9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div style=\"font-size: 40px\">\n",
    "main training loop\n",
    "</div>"
   ],
   "id": "20695f0fb90b7db9"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e142bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after Epoch 1: 18.18% Loss: 0.096%\n",
      "Accuracy after Epoch 2: 31.29% Loss: 0.079%\n",
      "Accuracy after Epoch 2: 31.29% Loss: 0.079%\n",
      "Accuracy after Epoch 3: 38.51% Loss: 0.070%\n",
      "Accuracy after Epoch 3: 38.51% Loss: 0.070%\n",
      "Accuracy after Epoch 4: 44.16% Loss: 0.064%\n",
      "Accuracy after Epoch 4: 44.16% Loss: 0.064%\n",
      "Accuracy after Epoch 5: 48.86% Loss: 0.058%\n",
      "Accuracy after Epoch 5: 48.86% Loss: 0.058%\n",
      "Accuracy after Epoch 6: 52.48% Loss: 0.054%\n",
      "Accuracy after Epoch 6: 52.48% Loss: 0.054%\n",
      "Accuracy after Epoch 7: 55.31% Loss: 0.050%\n",
      "Accuracy after Epoch 7: 55.31% Loss: 0.050%\n",
      "Accuracy after Epoch 8: 58.22% Loss: 0.047%\n",
      "Accuracy after Epoch 8: 58.22% Loss: 0.047%\n",
      "Accuracy after Epoch 9: 60.58% Loss: 0.044%\n",
      "Accuracy after Epoch 9: 60.58% Loss: 0.044%\n",
      "Accuracy after Epoch 10: 62.79% Loss: 0.042%\n",
      "Accuracy after Epoch 10: 62.79% Loss: 0.042%\n",
      "Accuracy after Epoch 11: 64.59% Loss: 0.039%\n",
      "Accuracy after Epoch 11: 64.59% Loss: 0.039%\n",
      "Accuracy after Epoch 12: 66.28% Loss: 0.037%\n",
      "Accuracy after Epoch 12: 66.28% Loss: 0.037%\n",
      "Accuracy after Epoch 13: 67.73% Loss: 0.035%\n",
      "Accuracy after Epoch 13: 67.73% Loss: 0.035%\n",
      "Accuracy after Epoch 14: 69.16% Loss: 0.034%\n",
      "Accuracy after Epoch 14: 69.16% Loss: 0.034%\n",
      "Accuracy after Epoch 15: 70.45% Loss: 0.032%\n",
      "Accuracy after Epoch 15: 70.45% Loss: 0.032%\n",
      "Accuracy after Epoch 16: 71.77% Loss: 0.031%\n",
      "Accuracy after Epoch 16: 71.77% Loss: 0.031%\n",
      "Accuracy after Epoch 17: 72.89% Loss: 0.029%\n",
      "Accuracy after Epoch 17: 72.89% Loss: 0.029%\n",
      "Accuracy after Epoch 18: 74.00% Loss: 0.028%\n",
      "Accuracy after Epoch 18: 74.00% Loss: 0.028%\n",
      "Accuracy after Epoch 19: 75.08% Loss: 0.027%\n",
      "Accuracy after Epoch 19: 75.08% Loss: 0.027%\n",
      "Accuracy after Epoch 20: 75.95% Loss: 0.026%\n",
      "Accuracy after Epoch 20: 75.95% Loss: 0.026%\n",
      "Accuracy after Epoch 21: 76.82% Loss: 0.025%\n",
      "Accuracy after Epoch 21: 76.82% Loss: 0.025%\n",
      "Accuracy after Epoch 22: 77.92% Loss: 0.023%\n",
      "Accuracy after Epoch 22: 77.92% Loss: 0.023%\n",
      "Accuracy after Epoch 23: 78.67% Loss: 0.023%\n",
      "Accuracy after Epoch 23: 78.67% Loss: 0.023%\n",
      "Accuracy after Epoch 24: 79.27% Loss: 0.022%\n",
      "Accuracy after Epoch 24: 79.27% Loss: 0.022%\n",
      "Accuracy after Epoch 25: 80.18% Loss: 0.021%\n",
      "Accuracy after Epoch 25: 80.18% Loss: 0.021%\n",
      "Accuracy after Epoch 26: 80.95% Loss: 0.020%\n",
      "Accuracy after Epoch 26: 80.95% Loss: 0.020%\n",
      "Accuracy after Epoch 27: 81.43% Loss: 0.019%\n",
      "Accuracy after Epoch 27: 81.43% Loss: 0.019%\n",
      "Accuracy after Epoch 28: 81.99% Loss: 0.019%\n",
      "Accuracy after Epoch 28: 81.99% Loss: 0.019%\n",
      "Accuracy after Epoch 29: 82.52% Loss: 0.018%\n",
      "Accuracy after Epoch 29: 82.52% Loss: 0.018%\n",
      "Accuracy after Epoch 30: 83.16% Loss: 0.017%\n",
      "Accuracy after Epoch 30: 83.16% Loss: 0.017%\n",
      "Accuracy after Epoch 31: 83.72% Loss: 0.017%\n",
      "Accuracy after Epoch 31: 83.72% Loss: 0.017%\n",
      "Accuracy after Epoch 32: 84.28% Loss: 0.016%\n",
      "Accuracy after Epoch 32: 84.28% Loss: 0.016%\n",
      "Accuracy after Epoch 33: 84.69% Loss: 0.016%\n",
      "Accuracy after Epoch 33: 84.69% Loss: 0.016%\n",
      "Accuracy after Epoch 34: 85.30% Loss: 0.015%\n",
      "Accuracy after Epoch 34: 85.30% Loss: 0.015%\n",
      "Accuracy after Epoch 35: 85.50% Loss: 0.015%\n",
      "Accuracy after Epoch 35: 85.50% Loss: 0.015%\n",
      "Accuracy after Epoch 36: 86.12% Loss: 0.014%\n",
      "Accuracy after Epoch 36: 86.12% Loss: 0.014%\n",
      "Accuracy after Epoch 37: 86.26% Loss: 0.014%\n",
      "Accuracy after Epoch 37: 86.26% Loss: 0.014%\n",
      "Accuracy after Epoch 38: 86.74% Loss: 0.014%\n",
      "Accuracy after Epoch 38: 86.74% Loss: 0.014%\n",
      "Accuracy after Epoch 39: 87.14% Loss: 0.013%\n",
      "Accuracy after Epoch 39: 87.14% Loss: 0.013%\n",
      "Accuracy after Epoch 40: 87.37% Loss: 0.013%\n",
      "Accuracy after Epoch 40: 87.37% Loss: 0.013%\n",
      "Accuracy after Epoch 41: 87.69% Loss: 0.013%\n",
      "Accuracy after Epoch 41: 87.69% Loss: 0.013%\n",
      "Accuracy after Epoch 42: 87.97% Loss: 0.012%\n",
      "Accuracy after Epoch 42: 87.97% Loss: 0.012%\n",
      "Accuracy after Epoch 43: 88.23% Loss: 0.012%\n",
      "Accuracy after Epoch 43: 88.23% Loss: 0.012%\n",
      "Accuracy after Epoch 44: 88.27% Loss: 0.012%\n",
      "Accuracy after Epoch 44: 88.27% Loss: 0.012%\n",
      "Accuracy after Epoch 45: 88.73% Loss: 0.012%\n",
      "Accuracy after Epoch 45: 88.73% Loss: 0.012%\n",
      "Accuracy after Epoch 46: 89.03% Loss: 0.011%\n",
      "Accuracy after Epoch 46: 89.03% Loss: 0.011%\n",
      "Accuracy after Epoch 47: 89.28% Loss: 0.011%\n",
      "Accuracy after Epoch 47: 89.28% Loss: 0.011%\n",
      "Accuracy after Epoch 48: 89.30% Loss: 0.011%\n",
      "Accuracy after Epoch 48: 89.30% Loss: 0.011%\n",
      "Accuracy after Epoch 49: 89.68% Loss: 0.011%\n",
      "Accuracy after Epoch 49: 89.68% Loss: 0.011%\n",
      "Accuracy after Epoch 50: 89.93% Loss: 0.011%\n",
      "Accuracy after Epoch 50: 89.93% Loss: 0.011%\n",
      "Accuracy after Epoch 51: 90.02% Loss: 0.010%\n",
      "Accuracy after Epoch 51: 90.02% Loss: 0.010%\n",
      "Accuracy after Epoch 52: 90.21% Loss: 0.010%\n",
      "Accuracy after Epoch 52: 90.21% Loss: 0.010%\n",
      "Accuracy after Epoch 53: 90.39% Loss: 0.010%\n",
      "Accuracy after Epoch 53: 90.39% Loss: 0.010%\n",
      "Accuracy after Epoch 54: 90.66% Loss: 0.010%\n",
      "Accuracy after Epoch 54: 90.66% Loss: 0.010%\n",
      "Accuracy after Epoch 55: 90.82% Loss: 0.010%\n",
      "Accuracy after Epoch 55: 90.82% Loss: 0.010%\n",
      "Accuracy after Epoch 56: 90.93% Loss: 0.010%\n",
      "Accuracy after Epoch 56: 90.93% Loss: 0.010%\n",
      "Accuracy after Epoch 57: 90.91% Loss: 0.009%\n",
      "Accuracy after Epoch 57: 90.91% Loss: 0.009%\n",
      "Accuracy after Epoch 58: 91.07% Loss: 0.009%\n",
      "Accuracy after Epoch 58: 91.07% Loss: 0.009%\n",
      "Accuracy after Epoch 59: 91.53% Loss: 0.009%\n",
      "Accuracy after Epoch 59: 91.53% Loss: 0.009%\n",
      "Accuracy after Epoch 60: 91.34% Loss: 0.009%\n",
      "Accuracy after Epoch 60: 91.34% Loss: 0.009%\n",
      "Accuracy after Epoch 61: 91.60% Loss: 0.009%\n",
      "Accuracy after Epoch 61: 91.60% Loss: 0.009%\n",
      "Accuracy after Epoch 62: 91.62% Loss: 0.009%\n",
      "Accuracy after Epoch 62: 91.62% Loss: 0.009%\n",
      "Accuracy after Epoch 63: 91.88% Loss: 0.009%\n",
      "Accuracy after Epoch 63: 91.88% Loss: 0.009%\n",
      "Accuracy after Epoch 64: 91.85% Loss: 0.008%\n",
      "Accuracy after Epoch 64: 91.85% Loss: 0.008%\n",
      "Accuracy after Epoch 65: 92.16% Loss: 0.008%\n",
      "Accuracy after Epoch 65: 92.16% Loss: 0.008%\n",
      "Accuracy after Epoch 66: 92.25% Loss: 0.008%\n",
      "Accuracy after Epoch 66: 92.25% Loss: 0.008%\n",
      "Accuracy after Epoch 67: 92.20% Loss: 0.008%\n",
      "Accuracy after Epoch 67: 92.20% Loss: 0.008%\n",
      "Accuracy after Epoch 68: 92.47% Loss: 0.008%\n",
      "Accuracy after Epoch 68: 92.47% Loss: 0.008%\n",
      "Accuracy after Epoch 69: 92.38% Loss: 0.008%\n",
      "Accuracy after Epoch 69: 92.38% Loss: 0.008%\n",
      "Accuracy after Epoch 70: 92.64% Loss: 0.008%\n",
      "Accuracy after Epoch 70: 92.64% Loss: 0.008%\n",
      "Accuracy after Epoch 71: 92.61% Loss: 0.008%\n",
      "Accuracy after Epoch 71: 92.61% Loss: 0.008%\n",
      "Accuracy after Epoch 72: 92.67% Loss: 0.008%\n",
      "Accuracy after Epoch 72: 92.67% Loss: 0.008%\n",
      "Accuracy after Epoch 73: 92.73% Loss: 0.008%\n",
      "Accuracy after Epoch 73: 92.73% Loss: 0.008%\n",
      "Accuracy after Epoch 74: 93.01% Loss: 0.008%\n",
      "Accuracy after Epoch 74: 93.01% Loss: 0.008%\n",
      "Accuracy after Epoch 75: 92.91% Loss: 0.008%\n",
      "Accuracy after Epoch 75: 92.91% Loss: 0.008%\n",
      "Accuracy after Epoch 76: 93.17% Loss: 0.007%\n",
      "Accuracy after Epoch 76: 93.17% Loss: 0.007%\n",
      "Accuracy after Epoch 77: 93.02% Loss: 0.008%\n",
      "Accuracy after Epoch 77: 93.02% Loss: 0.008%\n",
      "Accuracy after Epoch 78: 93.21% Loss: 0.007%\n",
      "Accuracy after Epoch 78: 93.21% Loss: 0.007%\n",
      "Accuracy after Epoch 79: 93.36% Loss: 0.007%\n",
      "Accuracy after Epoch 79: 93.36% Loss: 0.007%\n",
      "Accuracy after Epoch 80: 93.27% Loss: 0.007%\n",
      "Accuracy after Epoch 80: 93.27% Loss: 0.007%\n",
      "Accuracy after Epoch 81: 93.43% Loss: 0.007%\n",
      "Accuracy after Epoch 81: 93.43% Loss: 0.007%\n",
      "Accuracy after Epoch 82: 93.68% Loss: 0.007%\n",
      "Accuracy after Epoch 82: 93.68% Loss: 0.007%\n",
      "Accuracy after Epoch 83: 93.59% Loss: 0.007%\n",
      "Accuracy after Epoch 83: 93.59% Loss: 0.007%\n",
      "Accuracy after Epoch 84: 93.70% Loss: 0.007%\n",
      "Accuracy after Epoch 84: 93.70% Loss: 0.007%\n",
      "Accuracy after Epoch 85: 93.62% Loss: 0.007%\n",
      "Accuracy after Epoch 85: 93.62% Loss: 0.007%\n",
      "Accuracy after Epoch 86: 93.68% Loss: 0.007%\n",
      "Accuracy after Epoch 86: 93.68% Loss: 0.007%\n",
      "Accuracy after Epoch 87: 93.97% Loss: 0.007%\n",
      "Accuracy after Epoch 87: 93.97% Loss: 0.007%\n",
      "Accuracy after Epoch 88: 93.88% Loss: 0.007%\n",
      "Accuracy after Epoch 88: 93.88% Loss: 0.007%\n",
      "Accuracy after Epoch 89: 93.83% Loss: 0.007%\n",
      "Accuracy after Epoch 89: 93.83% Loss: 0.007%\n",
      "Accuracy after Epoch 90: 93.98% Loss: 0.007%\n",
      "Accuracy after Epoch 90: 93.98% Loss: 0.007%\n",
      "Accuracy after Epoch 91: 94.01% Loss: 0.007%\n",
      "Accuracy after Epoch 91: 94.01% Loss: 0.007%\n",
      "Accuracy after Epoch 92: 93.93% Loss: 0.007%\n",
      "Accuracy after Epoch 92: 93.93% Loss: 0.007%\n",
      "Accuracy after Epoch 93: 94.13% Loss: 0.007%\n",
      "Accuracy after Epoch 93: 94.13% Loss: 0.007%\n",
      "Accuracy after Epoch 94: 94.07% Loss: 0.006%\n",
      "Accuracy after Epoch 94: 94.07% Loss: 0.006%\n",
      "Accuracy after Epoch 95: 94.34% Loss: 0.006%\n",
      "Accuracy after Epoch 95: 94.34% Loss: 0.006%\n",
      "Accuracy after Epoch 96: 94.45% Loss: 0.006%\n",
      "Accuracy after Epoch 96: 94.45% Loss: 0.006%\n",
      "Accuracy after Epoch 97: 94.35% Loss: 0.006%\n",
      "Accuracy after Epoch 97: 94.35% Loss: 0.006%\n",
      "Accuracy after Epoch 98: 94.32% Loss: 0.006%\n",
      "Accuracy after Epoch 98: 94.32% Loss: 0.006%\n",
      "Accuracy after Epoch 99: 94.46% Loss: 0.006%\n",
      "Accuracy after Epoch 99: 94.46% Loss: 0.006%\n",
      "Accuracy after Epoch 100: 94.53% Loss: 0.006%\n",
      "Accuracy after Epoch 100: 94.53% Loss: 0.006%\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(trainset.classes)\n",
    "model = CNNModel(num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)\n",
    "\n",
    "def train_model(model, trainloader, valloader, criterion, optimizer, scheduler, start_epoch=0, num_epochs=10):\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    training_losses = []\n",
    "    training_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for epoch in range(start_epoch, start_epoch + num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            if i % 100 == 99:\n",
    "                elapsed_time = time.time() - start_time\n",
    "                accuracy = 100 * correct / total\n",
    "                print(f'Epoch {epoch+1}, Batch {i+1}, Loss: {running_loss/100:.3f}, Accuracy: {accuracy:.2f}%, Time: {elapsed_time:.2f}s')\n",
    "                running_loss = 0.0\n",
    "\n",
    "        print(f'Accuracy after Epoch {epoch+1}: {100 * correct / total:.2f}%')\n",
    "\n",
    "train_model(model, trainloader, criterion, optimizer, num_epochs=5)\n",
    "\n",
    "history = train_model(model, trainloader, valloader, criterion, optimizer, scheduler, start_epoch=50, num_epochs=20)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div style=\"font-size: 40px\">\n",
    "plot training history\n",
    "</div>"
   ],
   "id": "2b0efca878e80956"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_losses'], 'b-', label='Training')\n",
    "plt.plot(history['val_losses'], 'r-', label='Validation')\n",
    "plt.title('Loss During Training')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['train_accs'], 'b-', label='Training')\n",
    "plt.plot(history['val_accs'], 'r-', label='Validation')\n",
    "plt.title('Accuracy During Training')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "cd5b0729485de5c0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div style=\"font-size: 40px\">\n",
    "generate predictions\n",
    "</div>"
   ],
   "id": "e0381b1195a93a7b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model.load_state_dict(torch.load('main.pth'))\n",
    "model.eval()\n",
    "\n",
    "test_dir = \"dane/test_all/\"\n",
    "test_files = [f for f in os.listdir(test_dir)\n",
    "              if f.lower().endswith(('.jpeg', '.jpg', '.png', '.JPEG'))]\n",
    "\n",
    "print(f\"Found {len(test_files)} test images\")\n",
    "print(f\"Classes in training set: {full_dataset.classes}\")"
   ],
   "id": "ad4fa659b072542b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "predictions = []\n",
    "filenames = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for file in test_files:\n",
    "        img_path = os.path.join(test_dir, file)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        image_tensor = test_transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "        output = model(image_tensor)\n",
    "        _, pred = torch.max(output, 1)\n",
    "\n",
    "        base_name = os.path.splitext(file)[0]\n",
    "        filename_jpeg = f\"{base_name}.JPEG\"\n",
    "\n",
    "        predictions.append(pred.item())\n",
    "        filenames.append(filename_jpeg)\n",
    "\n",
    "        if len(predictions) % 100 == 0:\n",
    "            print(f\"Processed {len(predictions)}/{len(test_files)} images\")"
   ],
   "id": "67195fcc717bbaba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "with open('pred.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    for filename, pred in zip(filenames, predictions):\n",
    "        writer.writerow([filename, pred])"
   ],
   "id": "58055715e5c1d9fa"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
