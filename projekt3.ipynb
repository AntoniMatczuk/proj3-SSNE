{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "initial_id",
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2025-04-09T20:30:00.543627Z",
                    "start_time": "2025-04-09T20:29:56.320675Z"
                },
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "import torchvision.transforms as transforms\n",
                "from torchvision.datasets import ImageFolder\n",
                "from torch.utils.data import DataLoader\n",
                "import time\n",
                "import matplotlib.pyplot as plt\n",
                "from torchinfo import summary\n",
                "import json\n",
                "import os\n",
                "import shutil\n",
                "from torch.utils.data import random_split\n",
                "import csv\n",
                "from PIL import Image"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d8773f97620cd5b1",
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2025-04-09T20:31:03.356617Z",
                    "start_time": "2025-04-09T20:31:02.979838Z"
                }
            },
            "outputs": [],
            "source": [
                "train_transform = transforms.Compose([\n",
                "    transforms.Resize((64, 64)),\n",
                "    transforms.RandomHorizontalFlip(),\n",
                "    transforms.RandomRotation(10),\n",
                "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
                "])\n",
                "\n",
                "test_transform = transforms.Compose([\n",
                "    transforms.Resize((64, 64)),\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
                "])\n",
                "\n",
                "full_dataset = ImageFolder(\"dane/train/\", transform=train_transform)\n",
                "\n",
                "dataset_size = len(full_dataset)\n",
                "train_size = int(dataset_size * 0.92)\n",
                "val_size = dataset_size - train_size\n",
                "trainset, valset = random_split(full_dataset, [train_size, val_size])\n",
                "\n",
                "trainloader = DataLoader(trainset, batch_size=32, shuffle=True, num_workers=4)\n",
                "valloader = DataLoader(valset, batch_size=32, shuffle=False, num_workers=4)\n",
                "\n",
                "print(f\"Liczba klas: {len(full_dataset.classes)}\")\n",
                "print(f\"Nazwy klas: {full_dataset.classes}\")\n",
                "print(f\"Liczba obrazów treningowych: {len(trainset)}\")\n",
                "print(f\"Liczba obrazów walidacyjnych: {len(valset)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a2688c7e8fb10b0f",
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2025-04-09T20:31:37.200085Z",
                    "start_time": "2025-04-09T20:31:37.189466Z"
                }
            },
            "outputs": [],
            "source": [
                "class CNNModel(nn.Module):\n",
                "    def __init__(self, num_classes):\n",
                "        super(CNNModel, self).__init__()\n",
                "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
                "        self.bn1 = nn.BatchNorm2d(32)\n",
                "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
                "\n",
                "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
                "        self.bn2 = nn.BatchNorm2d(64)\n",
                "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
                "\n",
                "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
                "        self.bn3 = nn.BatchNorm2d(128)\n",
                "        self.pool3 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
                "\n",
                "        self.fc1 = nn.Linear(128 * 7 * 7, 512)\n",
                "        self.dropout = nn.Dropout(0.5)\n",
                "        self.fc2 = nn.Linear(512, num_classes)\n",
                "\n",
                "    def forward(self, x):\n",
                "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
                "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
                "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
                "\n",
                "        x = x.view(-1, 128 * 7 * 7)\n",
                "\n",
                "        x = F.relu(self.fc1(x))\n",
                "        x = self.dropout(x)\n",
                "        x = self.fc2(x)\n",
                "\n",
                "        return x"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d9a39403",
            "metadata": {},
            "outputs": [],
            "source": [
                "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
                "print(f\"Używane urządzenie: {device}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d63d6e14",
            "metadata": {},
            "outputs": [],
            "source": [
                "num_classes = len(full_dataset.classes)\n",
                "model = CNNModel(num_classes).to(device)\n",
                "\n",
                "model_path = 'model.pth'\n",
                "if os.path.exists(model_path):\n",
                "    print(f\"Loading existing model from {model_path}\")\n",
                "    model.load_state_dict(torch.load(model_path))\n",
                "else:\n",
                "    print(\"No existing model found. Initializing new model.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "28a2844a",
            "metadata": {},
            "outputs": [],
            "source": [
                "summary(model, input_size=(1, 3, 64, 64), verbose=2)\n",
                "\n",
                "model_stats = summary(\n",
                "    model,\n",
                "    input_size=(1, 3, 64, 64),\n",
                "    col_names=[\"input_size\", \"output_size\", \"num_params\", \"kernel_size\", \"mult_adds\"],\n",
                "    col_width=20,\n",
                "    row_settings=[\"var_names\"]\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# model.load_state_dict(torch.load('main.pth'))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "603acdcef363b06c",
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2025-04-09T20:36:59.388485Z",
                    "start_time": "2025-04-09T20:31:41.798386Z"
                }
            },
            "outputs": [],
            "source": [
                "criterion = nn.CrossEntropyLoss()\n",
                "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
                "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.7, verbose=True)\n",
                "\n",
                "\n",
                "def train_model(model, trainloader, valloader, criterion, optimizer, scheduler, start_epoch=0, num_epochs=10):\n",
                "    os.makedirs(\"models\", exist_ok=True)\n",
                "\n",
                "    model.train()\n",
                "    start_time = time.time()\n",
                "\n",
                "    training_losses = []\n",
                "    training_accuracies = []\n",
                "    val_losses = []\n",
                "    val_accuracies = []\n",
                "\n",
                "    for epoch in range(start_epoch, start_epoch + num_epochs):\n",
                "        model.train()\n",
                "        running_loss = 0.0\n",
                "        correct = 0\n",
                "        total = 0\n",
                "\n",
                "        batch_count = len(trainloader)\n",
                "        epoch_start = time.time()\n",
                "\n",
                "        for i, data in enumerate(trainloader, 0):\n",
                "            inputs, labels = data[0].to(device), data[1].to(device)\n",
                "\n",
                "            optimizer.zero_grad()\n",
                "\n",
                "            outputs = model(inputs)\n",
                "            loss = criterion(outputs, labels)\n",
                "            loss.backward()\n",
                "            optimizer.step()\n",
                "\n",
                "            running_loss += loss.item()\n",
                "            _, predicted = torch.max(outputs.data, 1)\n",
                "            total += labels.size(0)\n",
                "            correct += (predicted == labels).sum().item()\n",
                "\n",
                "            accuracy = 100 * correct / total\n",
                "            elapsed = time.time() - start_time\n",
                "            epoch_elapsed = time.time() - epoch_start\n",
                "            if (i + 1) % 50 == 0:\n",
                "                print(f\"\\rEpoch {epoch+1}/{start_epoch+num_epochs} | Batch {i+1}/{batch_count} | Loss: {running_loss/(i+1):.4f} | Acc: {accuracy:.2f}% | Epoch time: {epoch_elapsed:.1f}s | Total time: {elapsed:.1f}s\", end=\"\")\n",
                "\n",
                "        train_loss = running_loss / len(trainloader)\n",
                "        train_acc = 100 * correct / total\n",
                "        training_losses.append(train_loss)\n",
                "        training_accuracies.append(train_acc)\n",
                "\n",
                "        model.eval()\n",
                "        val_loss = 0.0\n",
                "        val_correct = 0\n",
                "        val_total = 0\n",
                "\n",
                "        with torch.no_grad():\n",
                "            for data in valloader:\n",
                "                inputs, labels = data[0].to(device), data[1].to(device)\n",
                "                outputs = model(inputs)\n",
                "                loss = criterion(outputs, labels)\n",
                "\n",
                "                val_loss += loss.item()\n",
                "                _, predicted = torch.max(outputs.data, 1)\n",
                "                val_total += labels.size(0)\n",
                "                val_correct += (predicted == labels).sum().item()\n",
                "\n",
                "        val_loss = val_loss / len(valloader)\n",
                "        val_acc = 100 * val_correct / val_total\n",
                "        val_losses.append(val_loss)\n",
                "        val_accuracies.append(val_acc)\n",
                "\n",
                "        scheduler.step(val_loss)\n",
                "\n",
                "        lr = optimizer.param_groups[0]['lr']\n",
                "        print(f\"\\nEpoch {epoch+1} - Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%, LR: {lr:.6f}\")\n",
                "\n",
                "        prev_backup = f\"backup_model_epoch_{epoch}.pth\"\n",
                "        if os.path.exists(prev_backup):\n",
                "            os.remove(prev_backup)\n",
                "\n",
                "        if epoch != start_epoch + num_epochs - 1:\n",
                "            backup_path = f\"backup_model_epoch_{epoch+1}.pth\"\n",
                "            torch.save(model.state_dict(), backup_path)\n",
                "\n",
                "        if (epoch + 1) % 5 == 0 or epoch == start_epoch + num_epochs - 1:\n",
                "            model_dir = f\"models/model_{epoch+1}\"\n",
                "            os.makedirs(model_dir, exist_ok=True)\n",
                "\n",
                "            model_path = f\"{model_dir}/model.pth\"\n",
                "            torch.save(model.state_dict(), model_path)\n",
                "\n",
                "            plt.figure(figsize=(12, 5))\n",
                "\n",
                "            plt.subplot(1, 2, 1)\n",
                "            plt.plot(training_losses, 'b-', label='Training')\n",
                "            plt.plot(val_losses, 'r-', label='Validation')\n",
                "            plt.title('Loss During Training')\n",
                "            plt.xlabel('Epochs')\n",
                "            plt.ylabel('Loss')\n",
                "            plt.legend()\n",
                "\n",
                "            plt.subplot(1, 2, 2)\n",
                "            plt.plot(training_accuracies, 'b-', label='Training')\n",
                "            plt.plot(val_accuracies, 'r-', label='Validation')\n",
                "            plt.title('Accuracy During Training')\n",
                "            plt.xlabel('Epochs')\n",
                "            plt.ylabel('Accuracy (%)')\n",
                "            plt.legend()\n",
                "\n",
                "            plt.tight_layout()\n",
                "            plt.savefig(f\"{model_dir}/training_history.png\")\n",
                "            plt.close()\n",
                "\n",
                "            training_data = {\n",
                "                'epoch': epoch + 1,\n",
                "                'train_losses': training_losses,\n",
                "                'train_accs': training_accuracies,\n",
                "                'val_losses': val_losses,\n",
                "                'val_accs': val_accuracies,\n",
                "                'final_lr': lr\n",
                "            }\n",
                "\n",
                "            with open(f\"{model_dir}/training_data.json\", 'w') as f:\n",
                "                json.dump(training_data, f)\n",
                "\n",
                "    torch.save(model.state_dict(), 'main.pth')\n",
                "    print(\"Training complete. Final model saved as main.pth\")\n",
                "\n",
                "    return {\n",
                "        'train_losses': training_losses,\n",
                "        'train_accs': training_accuracies,\n",
                "        'val_losses': val_losses,\n",
                "        'val_accs': val_accuracies\n",
                "    }\n",
                "\n",
                "history = train_model(model, trainloader, valloader, criterion, optimizer, scheduler, start_epoch=50, num_epochs=20)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ecd6869e",
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(12, 5))\n",
                "\n",
                "plt.subplot(1, 2, 1)\n",
                "plt.plot(history['train_losses'], 'b-', label='Training')\n",
                "plt.plot(history['val_losses'], 'r-', label='Validation')\n",
                "plt.title('Loss During Training')\n",
                "plt.xlabel('Epochs')\n",
                "plt.ylabel('Loss')\n",
                "plt.legend()\n",
                "\n",
                "plt.subplot(1, 2, 2)\n",
                "plt.plot(history['train_accs'], 'b-', label='Training')\n",
                "plt.plot(history['val_accs'], 'r-', label='Validation')\n",
                "plt.title('Accuracy During Training')\n",
                "plt.xlabel('Epochs')\n",
                "plt.ylabel('Accuracy (%)')\n",
                "plt.legend()\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e367ba2d",
            "metadata": {},
            "source": [
                "# generate the test set predictions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c53eb464",
            "metadata": {},
            "outputs": [],
            "source": [
                "model.load_state_dict(torch.load('main.pth'))\n",
                "model.eval()\n",
                "\n",
                "test_dir = \"dane/test_all/\"\n",
                "test_files = [f for f in os.listdir(test_dir)\n",
                "              if f.lower().endswith(('.jpeg', '.jpg', '.png', '.JPEG'))]\n",
                "\n",
                "print(f\"Found {len(test_files)} test images\")\n",
                "print(f\"Classes in training set: {full_dataset.classes}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "035961b4",
            "metadata": {},
            "outputs": [],
            "source": [
                "predictions = []\n",
                "filenames = []\n",
                "\n",
                "with torch.no_grad():\n",
                "    for file in test_files:\n",
                "        img_path = os.path.join(test_dir, file)\n",
                "        image = Image.open(img_path).convert('RGB')\n",
                "        image_tensor = test_transform(image).unsqueeze(0).to(device)\n",
                "\n",
                "        output = model(image_tensor)\n",
                "        _, pred = torch.max(output, 1)\n",
                "\n",
                "        base_name = os.path.splitext(file)[0]\n",
                "        filename_jpeg = f\"{base_name}.JPEG\"\n",
                "\n",
                "        predictions.append(pred.item())\n",
                "        filenames.append(filename_jpeg)\n",
                "\n",
                "        if len(predictions) % 100 == 0:\n",
                "            print(f\"Processed {len(predictions)}/{len(test_files)} images\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "59e84bc9",
            "metadata": {},
            "outputs": [],
            "source": [
                "with open('pred.csv', 'w', newline='') as csvfile:\n",
                "    writer = csv.writer(csvfile)\n",
                "    for filename, pred in zip(filenames, predictions):\n",
                "        writer.writerow([filename, pred])"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
