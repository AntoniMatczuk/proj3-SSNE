{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T20:30:00.543627Z",
     "start_time": "2025-04-09T20:29:56.320675Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "from torch.utils.data import random_split\n",
    "import csv\n",
    "from PIL import Image"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div style=\"font-size: 40px\">\n",
    "data preparation\n",
    "</div>"
   ],
   "id": "336875e4073ad735"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8773f97620cd5b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T20:31:03.356617Z",
     "start_time": "2025-04-09T20:31:02.979838Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba klas: 50\n",
      "Nazwy klas: ['acoustic', 'antenna', 'bacteria', 'battery', 'bean', 'beetle', 'bicycle', 'birch', 'bird', 'bomb', 'bread', 'bridge', 'camera', 'carbon', 'cat', 'corn', 'crab', 'crocodilian', 'echinoderm', 'egg', 'elephant', 'fish', 'flower', 'frog', 'fungus', 'gauge', 'hammer', 'icecream', 'kangaroo', 'memorial', 'monkey', 'motor', 'nest', 'palm', 'pizza', 'pot', 'printer', 'saw', 'snake', 'spice', 'spider', 'spoon', 'squash', 'swine', 'tea', 'tomato', 'towel', 'truck', 'turtle', 'worm']\n",
      "Liczba obrazów treningowych: 88011\n"
     ]
    }
   ],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "full_dataset = ImageFolder(\"train/\", transform=train_transform)\n",
    "\n",
    "dataset_size = len(full_dataset)\n",
    "train_size = int(dataset_size * 0.92)\n",
    "val_size = dataset_size - train_size\n",
    "trainset, valset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=32, shuffle=True, num_workers=4)\n",
    "valloader = DataLoader(valset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "print(f\"Number of classes: {len(full_dataset.classes)}\")\n",
    "print(f\"Class names: {full_dataset.classes}\")\n",
    "print(f\"training images count: {len(trainset)}\")\n",
    "print(f\"testing images count: {len(valset)}\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div style=\"font-size: 40px\">\n",
    "model architecture\n",
    "</div>"
   ],
   "id": "8c3ee1407648d00b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "\n",
    "        out += self.shortcut(residual)\n",
    "        out = F.relu(out)\n",
    "\n",
    "        return out"
   ],
   "id": "21ec7dd54c527998"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2688c7e8fb10b0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T20:31:37.200085Z",
     "start_time": "2025-04-09T20:31:37.189466Z"
    }
   },
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNNModel, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.res1 = ResidualBlock(32, 64, stride=1)\n",
    "        self.res2 = ResidualBlock(64, 128, stride=1)\n",
    "        self.res3 = ResidualBlock(128, 256, stride=1)\n",
    "        self.res4 = ResidualBlock(256, 512, stride=1)\n",
    "\n",
    "        self.fc1 = nn.Linear(512 * 2 * 2, 1024)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        self.fc2 = nn.Linear(1024, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "\n",
    "        x = self.pool(self.res1(x))\n",
    "        x = self.pool(self.res2(x))\n",
    "        x = self.pool(self.res3(x))\n",
    "        x = self.pool(self.res4(x))\n",
    "\n",
    "        x = x.view(-1, 512 * 2 * 2)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "603acdcef363b06c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T20:36:59.388485Z",
     "start_time": "2025-04-09T20:31:41.798386Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Używane urządzenie: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Used device: {device}\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "num_classes = len(full_dataset.classes)\n",
    "model = CNNModel(num_classes).to(device)\n",
    "\n",
    "model_path = 'model.pth'\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Loading existing model from {model_path}\")\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "else:\n",
    "    print(\"No existing model found. Initializing new model.\")"
   ],
   "id": "21a9b4df11a25ab9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div style=\"font-size: 40px\">\n",
    "main training loop\n",
    "</div>"
   ],
   "id": "20695f0fb90b7db9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e142bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(trainset.classes)\n",
    "model = CNNModel(num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)\n",
    "\n",
    "def train_model(model, trainloader, valloader, criterion, optimizer, scheduler, start_epoch=0, num_epochs=10):\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    training_losses = []\n",
    "    training_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for epoch in range(start_epoch, start_epoch + num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_loss = running_loss / len(trainloader)\n",
    "        train_acc = 100 * correct / total\n",
    "        training_losses.append(train_loss)\n",
    "        training_accuracies.append(train_acc)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in valloader:\n",
    "                inputs, labels = data[0].to(device), data[1].to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_loss = val_loss / len(valloader)\n",
    "        val_acc = 100 * val_correct / val_total\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        lr = optimizer.param_groups[0]['lr']\n",
    "        print(f\"\\nEpoch {epoch+1} - Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%, LR: {lr:.6f}\")\n",
    "\n",
    "        prev_backup = f\"backup_model_epoch_{epoch}.pth\"\n",
    "        if os.path.exists(prev_backup):\n",
    "            os.remove(prev_backup)\n",
    "\n",
    "        if epoch != start_epoch + num_epochs - 1:\n",
    "            backup_path = f\"backup_model_epoch_{epoch+1}.pth\"\n",
    "            torch.save(model.state_dict(), backup_path)\n",
    "\n",
    "        if (epoch + 1) % 5 == 0 or epoch == start_epoch + num_epochs - 1:\n",
    "            model_dir = f\"models/model_{epoch+1}\"\n",
    "            os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "            model_path = f\"{model_dir}/model.pth\"\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "\n",
    "            plt.figure(figsize=(12, 5))\n",
    "\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.plot(training_losses, 'b-', label='Training')\n",
    "            plt.plot(val_losses, 'r-', label='Validation')\n",
    "            plt.title('Loss During Training')\n",
    "            plt.xlabel('Epochs')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.legend()\n",
    "\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.plot(training_accuracies, 'b-', label='Training')\n",
    "            plt.plot(val_accuracies, 'r-', label='Validation')\n",
    "            plt.title('Accuracy During Training')\n",
    "            plt.xlabel('Epochs')\n",
    "            plt.ylabel('Accuracy (%)')\n",
    "            plt.legend()\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"{model_dir}/training_history.png\")\n",
    "            plt.close()\n",
    "\n",
    "            training_data = {\n",
    "                'epoch': epoch + 1,\n",
    "                'train_losses': training_losses,\n",
    "                'train_accs': training_accuracies,\n",
    "                'val_losses': val_losses,\n",
    "                'val_accs': val_accuracies,\n",
    "                'final_lr': lr\n",
    "            }\n",
    "\n",
    "            with open(f\"{model_dir}/training_data.json\", 'w') as f:\n",
    "                json.dump(training_data, f)\n",
    "\n",
    "    torch.save(model.state_dict(), 'main.pth')\n",
    "    print(\"Training complete. Final model saved as main.pth\")\n",
    "\n",
    "    return {\n",
    "        'train_losses': training_losses,\n",
    "        'train_accs': training_accuracies,\n",
    "        'val_losses': val_losses,\n",
    "        'val_accs': val_accuracies\n",
    "    }\n",
    "\n",
    "history = train_model(model, trainloader, valloader, criterion, optimizer, scheduler, start_epoch=50, num_epochs=20)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div style=\"font-size: 40px\">\n",
    "plot training history\n",
    "</div>"
   ],
   "id": "2b0efca878e80956"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_losses'], 'b-', label='Training')\n",
    "plt.plot(history['val_losses'], 'r-', label='Validation')\n",
    "plt.title('Loss During Training')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['train_accs'], 'b-', label='Training')\n",
    "plt.plot(history['val_accs'], 'r-', label='Validation')\n",
    "plt.title('Accuracy During Training')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "cd5b0729485de5c0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "<div style=\"font-size: 40px\">\n",
    "generate predictions\n",
    "</div>"
   ],
   "id": "e0381b1195a93a7b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model.load_state_dict(torch.load('main.pth'))\n",
    "model.eval()\n",
    "\n",
    "test_dir = \"dane/test_all/\"\n",
    "test_files = [f for f in os.listdir(test_dir)\n",
    "              if f.lower().endswith(('.jpeg', '.jpg', '.png', '.JPEG'))]\n",
    "\n",
    "print(f\"Found {len(test_files)} test images\")\n",
    "print(f\"Classes in training set: {full_dataset.classes}\")"
   ],
   "id": "ad4fa659b072542b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "predictions = []\n",
    "filenames = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for file in test_files:\n",
    "        img_path = os.path.join(test_dir, file)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        image_tensor = test_transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "        output = model(image_tensor)\n",
    "        _, pred = torch.max(output, 1)\n",
    "\n",
    "        base_name = os.path.splitext(file)[0]\n",
    "        filename_jpeg = f\"{base_name}.JPEG\"\n",
    "\n",
    "        predictions.append(pred.item())\n",
    "        filenames.append(filename_jpeg)\n",
    "\n",
    "        if len(predictions) % 100 == 0:\n",
    "            print(f\"Processed {len(predictions)}/{len(test_files)} images\")"
   ],
   "id": "67195fcc717bbaba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "with open('pred.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    for filename, pred in zip(filenames, predictions):\n",
    "        writer.writerow([filename, pred])"
   ],
   "id": "58055715e5c1d9fa"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
